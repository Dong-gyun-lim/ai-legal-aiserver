# filename: law_api_fetch.py
import os
import re
import json
import html
import requests
from pathlib import Path
from dotenv import load_dotenv
from typing import List, Dict, Any, Optional

# =========================
# ğŸ”§ í™˜ê²½ì„¤ì •
# =========================
load_dotenv()
LAW_OC = os.getenv("LAW_OC")
if not LAW_OC:
    raise RuntimeError("í™˜ê²½ë³€ìˆ˜ LAW_OC ê°€ ì—†ìŠµë‹ˆë‹¤. .envì— LAW_OC=... ë¥¼ ì„¤ì •í•˜ì„¸ìš”.")

LIST_URL = "https://www.law.go.kr/DRF/lawSearch.do"
DETAIL_URL = "https://www.law.go.kr/DRF/lawService.do"
OUT_DIR = Path("out")
OUT_DIR.mkdir(parents=True, exist_ok=True)

# =========================
# ğŸ”¹ ìœ í‹¸ í•¨ìˆ˜
# =========================
CANDIDATE_ID_KEYS = [
    "íŒë¡€ì •ë³´ì¼ë ¨ë²ˆí˜¸", "íŒë¡€ì¼ë ¨ë²ˆí˜¸", "íŒë¡€ID", "precSeq", "precId", "ID"
]

def clean_html(s: Any) -> Any:
    """HTML íƒœê·¸ ì œê±° ë° ê°œí–‰ ì²˜ë¦¬"""
    if not isinstance(s, str):
        return s
    s = html.unescape(s)
    s = s.replace("<br/>", "\n").replace("<br>", "\n")
    s = re.sub(r"<[^>]+>", "", s)
    return s.strip()

def extract_prec_id(item: Dict[str, Any]) -> Optional[str]:
    """íŒë¡€ì •ë³´ì¼ë ¨ë²ˆí˜¸ ì¶”ì¶œ (ì—¬ëŸ¬ í›„ë³´ í‚¤ ê²€ì‚¬)"""
    for k in CANDIDATE_ID_KEYS:
        if k in item and item[k]:
            return str(item[k])
    for k, v in item.items():
        if isinstance(k, str) and "ì¼ë ¨ë²ˆí˜¸" in k and v:
            return str(v)
    return None

def extract_year(date_str: Optional[str]) -> Optional[int]:
    """'YYYYMMDD' ë˜ëŠ” 'YYYY.MM.DD' í˜•ì‹ì—ì„œ ì—°ë„ ì¶”ì¶œ"""
    if not date_str:
        return None
    m = re.search(r"(19|20)\d{2}", str(date_str))
    return int(m.group()) if m else None

# dat_srn_nm='ë²•ì›ë„ì„œê´€' â†’ ë²•ì›ë„ì„œê´€ì´ ì •ì œÂ·ê³µê°œí•œ ê³µì‹ íŒë¡€ DBë§Œ ê²€ìƒ‰ (í’ˆì§ˆ ì•ˆì •)
# ë¯¸ì§€ì • ì‹œ: ëŒ€ë²•ì›/í—Œì¬ ë“± í†µí•©ê²€ìƒ‰ (ì¤‘ë³µ/ë¹„ì •í˜• ë°ì´í„° í¬í•¨ ê°€ëŠ¥)
def fetch_case_list_page(keyword: str, page: int, display: int = 100,
                         dat_srn_nm: Optional[str] = "ë²•ì›ë„ì„œê´€",
                         sort: str = "ddes") -> Dict[str, Any]:
    """íŒë¡€ ëª©ë¡ 1í˜ì´ì§€ ì¡°íšŒ"""
    params = {
        "OC": LAW_OC,
        "target": "prec",
        "type": "JSON",
        "search": "1",
        "query": keyword,
        "display": display,
        "page": page,
        "sort": sort,
    }
    if dat_srn_nm:
        params["datSrnNm"] = dat_srn_nm

    res = requests.get(LIST_URL, params=params, timeout=20)
    res.raise_for_status()
    return res.json()

def fetch_case_list_all(keyword: str, limit: int = 1000,
                        dat_srn_nm: Optional[str] = "ë²•ì›ë„ì„œê´€") -> List[Dict[str, Any]]:
    """í˜ì´ì§€ë„¤ì´ì…˜ìœ¼ë¡œ ì „ì²´ íŒë¡€ ëª©ë¡ ì¡°íšŒ"""
    collected: List[Dict[str, Any]] = []
    page = 1
    per_page = 100

    while len(collected) < limit:
        data = fetch_case_list_page(keyword, page=page, display=per_page, dat_srn_nm=dat_srn_nm)
        prec_block = data.get("PrecSearch", {})
        items = prec_block.get("prec")

        if not items:
            break
        if isinstance(items, dict):
            items = [items]

        collected.extend(items)

        total_cnt = prec_block.get("totalCnt")
        try:
            total_cnt = int(total_cnt) if total_cnt else None
        except Exception:
            total_cnt = None

        if len(items) < per_page or (total_cnt and len(collected) >= total_cnt):
            break
        page += 1

    if len(collected) > limit:
        collected = collected[:limit]
    return collected

def fetch_case_detail(prec_id: str) -> Optional[Dict[str, Any]]:
    """íŠ¹ì • íŒë¡€ ë³¸ë¬¸ ì¡°íšŒ"""
    params = {
        "OC": LAW_OC,
        "target": "prec",
        "type": "JSON",
        "ID": prec_id,
    }
    res = requests.get(DETAIL_URL, params=params, timeout=20)
    res.raise_for_status()
    data = res.json()
    return data.get("PrecService")

def save_json(path: Path, obj: Any):
    path.write_text(json.dumps(obj, ensure_ascii=False, indent=2), encoding="utf-8")

# =========================
# ğŸš€ ë©”ì¸ ì‹¤í–‰
# =========================
def main():
    keyword = "ì´í˜¼"
    max_results = 500
    dat_srn_nm = "ë²•ì›ë„ì„œê´€"
    min_year = 2000  # âœ… 2000ë…„ ì´í›„ íŒë¡€ë§Œ ìˆ˜ì§‘

    print(f"ğŸ“¡ '{keyword}' íŒë¡€ {max_results}ê±´ê¹Œì§€ ìˆ˜ì§‘ ì‹œì‘ (ì†ŒìŠ¤={dat_srn_nm or 'ì „ì²´'})")
    items = fetch_case_list_all(keyword, limit=max_results * 2, dat_srn_nm=dat_srn_nm)  # ì—¬ìœ  í™•ë³´
    print(f"âœ… ì›ë³¸ ëª©ë¡ ìˆ˜ì§‘ ì™„ë£Œ: {len(items)}ê±´")

    # ğŸ§¹ 2000ë…„ ì´í›„ íŒë¡€ë§Œ í•„í„°ë§
    filtered = []
    for it in items:
        year = extract_year(it.get("ì„ ê³ ì¼ì"))
        if year and year >= min_year:
            filtered.append(it)
    print(f"ğŸ“… {min_year}ë…„ ì´í›„ íŒë¡€ë§Œ ë‚¨ê¹€: {len(filtered)}ê±´")

    # ìµœëŒ€ 500ê±´ê¹Œì§€ë§Œ ì‚¬ìš©
    items = filtered[:max_results]

    # 1ï¸âƒ£ ëª©ë¡ ìš”ì•½ ì €ì¥
    list_summary = []
    for it in items:
        pid = extract_prec_id(it)
        list_summary.append({
            "ì‚¬ê±´ëª…": it.get("ì‚¬ê±´ëª…"),
            "íŒë¡€ì •ë³´ì¼ë ¨ë²ˆí˜¸": pid,
            "ì‚¬ê±´ë²ˆí˜¸": it.get("ì‚¬ê±´ë²ˆí˜¸"),
            "ì„ ê³ ì¼ì": it.get("ì„ ê³ ì¼ì"),
            "ë²•ì›ëª…": it.get("ë²•ì›ëª…"),
        })
    save_json(OUT_DIR / f"list_{keyword}.json", list_summary)
    print(f"ğŸ’¾ ëª©ë¡ ì €ì¥ ì™„ë£Œ: out/list_{keyword}.json")

    # 2ï¸âƒ£ ë³¸ë¬¸ ìˆ˜ì§‘ (ì›ë³¸ / ì •ë¦¬ë³¸)
    raw_all = []
    cleaned_all = []
    missing = []

    for i, it in enumerate(items, 1):
        pid = extract_prec_id(it)
        if not pid:
            continue
        detail = fetch_case_detail(pid)
        if not detail:
            missing.append({"id": pid, "case_name": it.get("ì‚¬ê±´ëª…")})
            continue

        raw_all.append({"id": pid, "case_name": detail.get("ì‚¬ê±´ëª…"), "data": detail})
        cleaned = {k: clean_html(v) for k, v in detail.items()}
        cleaned_all.append({"id": pid, "case_name": detail.get("ì‚¬ê±´ëª…"), "data": cleaned})
        print(f"  [{i}/{len(items)}] {pid} {detail.get('ì‚¬ê±´ëª…')} ìˆ˜ì§‘ ì™„ë£Œ")

    save_json(OUT_DIR / f"precedents_raw_{keyword}.json", raw_all)
    save_json(OUT_DIR / f"precedents_cleaned_{keyword}.json", cleaned_all)
    if missing:
        save_json(OUT_DIR / f"missing_{keyword}.json", missing)

    print(f"ğŸ“˜ ë³¸ë¬¸ ì›ë³¸ ì €ì¥ ì™„ë£Œ: out/precedents_raw_{keyword}.json")
    print(f"ğŸ“— ë³¸ë¬¸ ì •ë¦¬ë³¸ ì €ì¥ ì™„ë£Œ: out/precedents_cleaned_{keyword}.json")
    print(f"ğŸ“‚ ì¶œë ¥ í´ë”: {OUT_DIR.resolve()}")

if __name__ == "__main__":
    main()
